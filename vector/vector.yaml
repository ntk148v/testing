# ========================================================================= Sources
#
# A source defines where Vector collects log data.
# The 'files' source type tails log files from the host machine.
# =========================================================================
sources:
  host_logs:
    type: file
    include:
      - /var/log/syslog
      - /var/log/auth.log
  demo_logs:
    type: demo_logs
    format: json
    decoding:
      codec: json

# =========================================================================
# Transforms
#
# A transform modifies the log data before it's sent to the sink.
# This transform adds a timestamp and a "job" label, which are
# recommended for the clickhouse schema.
# =========================================================================
transforms:
  vector_to_multi:
    type: remap
    inputs:
      - host_logs
    source: |
      .timestamp = format_timestamp!(now(), "%F %T")
      .host = get_env_var!("HOSTNAME")
      .job = "host_logs"

# =========================================================================
# Sinks
#
# A sink defines the destination for collected log data.
# =========================================================================
sinks:
  clickhouse_sink1:
    type: clickhouse
    compression: none
    inputs:
      - vector_to_multi
    endpoint: http://clickhouse:8123
    database: logs
    table: syslog
    auth:
      strategy: basic
      user: user
      password: password
    buffer:
      when_full: drop_newest
  victorialogs_sink1:
    type: elasticsearch
    inputs:
      - vector_to_multi
    endpoints:
      - "http://victorialogs:9428/insert/elasticsearch/"
    api_version: v8
    compression: gzip
    healthcheck:
      enabled: false
    query:
      _msg_field: message
      _time_field: timestamp
      _stream_fields: host,container_name
  victorialogs_sink2:
    type: elasticsearch
    inputs:
      - demo_logs
    endpoints:
      - "http://victorialogs:9428/insert/elasticsearch/"
    api_version: v8
    compression: gzip
    healthcheck:
      enabled: false
    query:
      _msg_field: referer
      _time_field: event_time
      _stream_fields: host,bytes,method,protocol,request,status,user-identifier,event_time,referer
  clickhouse_sink2:
    type: clickhouse
    compression: none
    inputs:
      - demo_logs
    endpoint: http://clickhouse:8123
    database: logs
    table: demo
    auth:
      strategy: basic
      user: user
      password: password
    buffer:
      when_full: drop_newest
  elasticsearch_sink1:
    type: elasticsearch
    inputs:
      - vector_to_multi
    endpoints:
      - http://elasticsearch:9200
    bulk:
      index: syslog
  elasticsearch_sink2:
    type: elasticsearch
    inputs:
      - demo_logs
    endpoints:
      - http://elasticsearch:9200
    bulk:
      index: demo
